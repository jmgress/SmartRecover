# LLM Provider Configuration
# Specify which provider to use: "openai", "gemini", or "ollama"
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo

# Google Gemini Configuration
GOOGLE_API_KEY=your-google-api-key-here
GEMINI_MODEL=gemini-pro

# Ollama Configuration (for local LLMs)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Logging Configuration
# Log level options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
# Enable verbose logging (overrides LOG_LEVEL to DEBUG)
LOG_VERBOSE=false
# Path to log file (optional, leave empty to disable file logging)
LOG_FILE=
